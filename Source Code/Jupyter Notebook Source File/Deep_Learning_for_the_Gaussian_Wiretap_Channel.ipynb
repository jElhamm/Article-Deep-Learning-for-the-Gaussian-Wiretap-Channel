{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5f0eMsWPLBB4"
      },
      "outputs": [],
      "source": [
        "#***********************************************************************************************************************************************\n",
        "#                                                                                                                                              *\n",
        "#                                                 Deep Learning for the Gaussian Wiretap Channel                                               *\n",
        "#                              This code implements a communication system that utilizes autoencoder models for secure communication.          *\n",
        "#          The system includes an encoder, Bob's decoder, and Eve's decoder that are trained to communicate securely over a noisy channel.     *\n",
        "#                                                                                                                                              *\n",
        "#   Here is a brief explanation of the code:                                                                                                   *\n",
        "#                                                                                                                                              *\n",
        "# - The code first sets up the necessary libraries, constants, and definitions for the neural network models.                                  *\n",
        "# - It defines utility functions, layers, and models for the encoder and decoders.                                                             *\n",
        "# - It includes training methods for training Bob and Eve's decoders, as well as for the security training phase using k-means clustering.     *\n",
        "# - Evaluation functions to calculate Bit Error Rates for different Signal-to-Noise Ratios (SNR) are included.                                 *\n",
        "# - The code also includes functions for testing and visualization, such as plotting loss and encoding patterns.                               *\n",
        "# - It tests the autoencoder models with normal data, then creates a secure encoding using k-means clustering.                                 *\n",
        "#   for the security procedure and tests the secure communication.                                                                             *\n",
        "# - the results are visualized in a plot showing the Symbol Error Rate versus SNR for Bob and Eve in both the traditional and secure setups.   *\n",
        "#                                                                                                                                              *\n",
        "#***********************************************************************************************************************************************"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "from scipy import special\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from EqualGroupsKMeans import EqualGroupsKMeans\n",
        "\n",
        "\n",
        "# Initialize random seeds AND Define Constants\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "M = 16\n",
        "n = 16\n",
        "k = int(np.log2(M))\n",
        "M_sec = 4\n",
        "SAMPLE_SIZE = 50000\n",
        "TRAINING_SNR = 10\n",
        "messages = np.random.randint(M, size=SAMPLE_SIZE)                                                               # Generate random messages\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False, categories=[range(M)])                                     # Encode messages using OneHotEncoder\n",
        "data_oneH = one_hot_encoder.fit_transform(messages.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "vRR1fE57LKCI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomFunctions:\n",
        "    @staticmethod\n",
        "    def snr_to_noise(snrdb):                                                                                    # Convert SNR in dB to noise standard deviation\n",
        "        snr = 10**(snrdb/10)\n",
        "        noise_std = 1/np.sqrt(2*snr)\n",
        "        return noise_std\n",
        "\n",
        "    @staticmethod\n",
        "    def B_Ber(input_msg, msg):                                                                                  # Calculate bit error rate from input and predicted messages\n",
        "        pred_error = tf.not_equal(tf.argmax(msg, 1), tf.argmax(input_msg, 1))\n",
        "        bber = tf.reduce_mean(tf.cast(pred_error, tf.float32))\n",
        "        return bber\n",
        "\n",
        "    @staticmethod\n",
        "    def random_batch(X, batch_size=32):                                                                         # Get a random batch of data from X\n",
        "        idx = np.random.randint(len(X), size=batch_size)\n",
        "        return X[idx]"
      ],
      "metadata": {
        "id": "pwlyrTj3LQV_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_std = CustomFunctions.snr_to_noise(TRAINING_SNR)                                                          # Convert SNR to noise standard deviation for training data\n",
        "noise_std_eve = CustomFunctions.snr_to_noise(7)                                                                 # Convert SNR to noise standard deviation for Eve channel\n",
        "\n",
        "class CustomLayers:\n",
        "    norm_layer = keras.layers.Lambda(lambda x: tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x)))))                                 # Normalize layer\n",
        "    shape_layer = keras.layers.Lambda(lambda x: tf.reshape(x, shape=[-1, 2, n]))                                                      # Reshape layer for 3D input tensor\n",
        "    shape_layer2 = keras.layers.Lambda(lambda x: tf.reshape(x, shape=[-1, 2*n]))                                                      # Reshape layer for 2D input tensor\n",
        "    channel_layer = keras.layers.Lambda(lambda x: tf.add(x, tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)))               # adding noise according\n",
        "    channel_layer_eve = keras.layers.Lambda(lambda x: tf.add(x, tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std_eve)))       # adding noise according"
      ],
      "metadata": {
        "id": "XtmWRe6RLSLm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Models:\n",
        "    # Encoder model architecture\n",
        "    encoder = keras.models.Sequential([\n",
        "        keras.layers.InputLayer(input_shape=[M]),                                                               # Input layer\n",
        "        keras.layers.Dense(M, activation=\"elu\"),                                                                # Dense layer with ELU activation\n",
        "        keras.layers.Dense(2*n, activation=None),                                                               # Dense layer without activation\n",
        "        CustomLayers.shape_layer,                                                                               # Reshape layer\n",
        "        CustomLayers.norm_layer                                                                                 # Normalize layer\n",
        "    ])\n",
        "    # Decoder model architecture for Bob\n",
        "    decoder_bob = keras.models.Sequential([\n",
        "        keras.layers.InputLayer(input_shape=[2, n]),                                                            # Input layer with 3D input tensor\n",
        "        CustomLayers.shape_layer2,                                                                              # Reshape layer for 2D input tensor\n",
        "        keras.layers.Dense(M, activation=\"elu\"),                                                                # Dense layer with ELU activation\n",
        "        keras.layers.Dense(M, activation=\"softmax\")                                                             # Dense layer with softmax activation\n",
        "    ])\n",
        "    # Decoder model architecture for Eve\n",
        "    decoder_eve = keras.models.Sequential([\n",
        "        keras.layers.InputLayer(input_shape=[2, n]),                                                            # Input layer with 3D input tensor\n",
        "        CustomLayers.shape_layer2,                                                                              # Reshape layer for 2D input tensor\n",
        "        keras.layers.Dense(M, activation=\"elu\"),                                                                # Dense layer with ELU activation\n",
        "        keras.layers.Dense(M, activation=\"softmax\")                                                             # Dense layer with softmax activation\n",
        "    ])"
      ],
      "metadata": {
        "id": "6Z_VEuuoLVAd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Training:\n",
        "    @staticmethod\n",
        "    def train_Bob(n_epochs=5, n_steps=20, plot_encoding=True, only_decoder=False):\n",
        "        for epoch in range(1, n_epochs + 1):                                                                    # Loop over epochs\n",
        "            print(\"Training Bob in Epoch {}/{}\".format(epoch, n_epochs))                                        # Print epoch progress\n",
        "            for step in range(1, n_steps + 1):                                                                  # Loop over steps\n",
        "                X_batch  = CustomFunctions.random_batch(data_oneH, batch_size)                                  # Get random batch\n",
        "                with tf.GradientTape() as tape:                                                                 # Record gradients\n",
        "                    y_pred = autoencoder_bob(X_batch, training=True)                                            # Predict\n",
        "                    main_loss = tf.reduce_mean(loss_fn(X_batch, y_pred))                                        # Calculate loss\n",
        "                    loss = main_loss                                                                            # Assign loss\n",
        "                if only_decoder:                                                                                # If training only decoder\n",
        "                    gradients = tape.gradient(loss, Models.decoder_bob.trainable_variables)                     # Calculate gradients\n",
        "                    optimizer.apply_gradients(zip(gradients, Models.decoder_bob.trainable_variables))           # Apply gradients to decoder\n",
        "                else:                                                                                           # If training full autoencoder\n",
        "                    gradients = tape.gradient(loss, autoencoder_bob.trainable_variables)                        # Calculate gradients\n",
        "                    optimizer.apply_gradients(zip(gradients, autoencoder_bob.trainable_variables))              # Apply gradients to autoencoder\n",
        "                mean_loss(loss)                                                                                 # Track mean loss\n",
        "                plot_loss(step, epoch, mean_loss, X_batch, y_pred, plot_encoding)                               # Plot loss\n",
        "            plot_batch_loss(epoch, mean_loss, X_batch, y_pred)                                                  # Plot batch loss\n",
        "#*********************************************************************************************************************************************************************\n",
        "    @staticmethod\n",
        "    def train_Eve(n_epochs=5, iterations=20, plot_encoding=True):\n",
        "        for epoch in range(1, n_epochs + 1):                                                                    # Loop through each epoch\n",
        "            print(\"Training Eve in Epoch {}/{}\".format(epoch, n_epochs))                                        # Display current epoch\n",
        "            for step in range(1, n_steps + 1):                                                                  # Loop through each step within the epoch\n",
        "                X_batch  = CustomFunctions.random_batch(data_oneH, batch_size)                                  # Get a random batch of data\n",
        "                with tf.GradientTape() as tape:                                                                 # Record operations for automatic differentiation\n",
        "                    y_pred = autoencoder_eve(X_batch, training=True)                                            # Forward pass through autoencoder\n",
        "                    main_loss = tf.reduce_mean(loss_fn(X_batch, y_pred))                                        # Calculate main loss\n",
        "                    loss = main_loss                                                                            # Total loss is the main loss\n",
        "                gradients = tape.gradient(loss, Models.decoder_eve.trainable_variables)                         # Compute gradients\n",
        "                optimizer.apply_gradients(zip(gradients, Models.decoder_eve.trainable_variables))               # Update model parameters using optimizer\n",
        "                mean_loss(loss)                                                                                 # Compute mean loss\n",
        "                plot_loss(step, epoch, mean_loss, X_batch, y_pred, plot_encoding)                               # Plot loss and encoding (if specified)\n",
        "            plot_batch_loss(epoch, mean_loss, X_batch, y_pred)                                                  # Plot batch loss for the epoch\n",
        "#*********************************************************************************************************************************************************************\n",
        "    @staticmethod\n",
        "    def init_kmeans(symM=16, satellites=4, n=100):\n",
        "        '''Initializes equal sized clusters with the whole message set'''\n",
        "        inp = np.eye(symM, dtype=int)                                                                           # Generate one-hot encoded input vectors\n",
        "        unit_codewords = Models.encoder.predict(inp)                                                            # Get unit codewords using the encoder model\n",
        "        kmeans = EqualGroupsKMeans(n_clusters=satellites)                                                       # Apply k-means clustering\n",
        "        kmeans.fit(unit_codewords.reshape(symM,2*n))\n",
        "        return kmeans\n",
        "#*********************************************************************************************************************************************************************\n",
        "    @staticmethod\n",
        "    def generate_mat(kmeans_labels, satellites=4, symM=16):\n",
        "        '''Generates the matrix for equalizing the input distribution on Eve's side'''\n",
        "        gen_matrix = np.zeros((symM, symM))                                                                     # Initialize the generation matrix\n",
        "        for j in range(satellites):                                                                             # Iterate over each cluster\n",
        "            for i in range(symM):                                                                               # Iterate over each symbol\n",
        "                if kmeans_labels[i] == j:                                                                       # Check if the symbol belongs to the current cluster\n",
        "                    for k in range(symM):                                                                       # Adjust the matrix for equalization\n",
        "                        if kmeans_labels[k] == j:\n",
        "                            gen_matrix[i, k] = 1 / satellites\n",
        "        gen_mat = tf.cast(gen_matrix, tf.float64)                                                               # Convert the matrix to float64 datatype\n",
        "        return gen_mat\n",
        "#*********************************************************************************************************************************************************************\n",
        "    @staticmethod\n",
        "    def train_Secure(kmeans_labels, n_epochs=5, iterations=20, alpha=0.7, plot_encoding=True):\n",
        "        generator_matrix = Training.generate_mat(kmeans_labels, M_sec, M)                                       # Generate transformation matrix based on KMeans labels\n",
        "        for epoch in range(1, n_epochs + 1):                                                                    # Iterate over epochs\n",
        "            print(\"Training for Security in Epoch {}/{}\".format(epoch, n_epochs))\n",
        "            for step in range(1, iterations + 1):                                                               # Iterate over steps\n",
        "                X_batch  = CustomFunctions.random_batch(data_oneH, batch_size)                                  # Generate random batch of data\n",
        "                x_batch_s= tf.matmul(X_batch, generator_matrix)                                                 # Transform input batch\n",
        "                with tf.GradientTape() as tape:                                                                 # Calculate predictions for Bob and Eve\n",
        "                    y_pred_bob = autoencoder_bob(X_batch, training=True)\n",
        "                    y_pred_eve = autoencoder_eve(X_batch, training=False)\n",
        "                    loss_bob = tf.reduce_mean(loss_fn(X_batch, y_pred_bob))                                     # Calculate losses for Bob and Eve\n",
        "                    loss_eve = tf.reduce_mean(loss_fn(x_batch_s, y_pred_eve))\n",
        "                    loss_sec =  (1-alpha)*loss_bob + alpha*loss_eve                                             # Combine losses to form security loss\n",
        "                gradients = tape.gradient(loss_sec, autoencoder_bob.trainable_variables)                        # Calculate gradients and apply to update Bob's autoencoder\n",
        "                optimizer.apply_gradients(zip(gradients, autoencoder_bob.trainable_variables))\n",
        "                mean_loss(loss_sec)                                                                             # Update mean loss and plot loss\n",
        "                plot_loss(step, epoch, mean_loss, X_batch, y_pred_bob, plot_encoding)\n",
        "            plot_batch_loss(epoch, mean_loss, X_batch, y_pred_bob)                                              # Plot batch loss for each epoch"
      ],
      "metadata": {
        "id": "bXi0v_9TLYl-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluation:\n",
        "    @staticmethod\n",
        "    def Test_AE(data):\n",
        "        '''Calculate Bit Error for varying SNRs'''\n",
        "        snr_range = np.linspace(0, 15, 30)                                                                      # SNR range from 0 to 15 with 30 points\n",
        "        bber_vec_bob = [None] * len(snr_range)                                                                  # Initializing a list for Bob's Bit Error Rate\n",
        "        bber_vec_eve = [None] * len(snr_range)                                                                  # Initializing a list for Eve's Bit Error Rate\n",
        "        for db in range(len(snr_range)):\n",
        "            noise_std = CustomFunctions.snr_to_noise(snr_range[db])                                             # Calculate noise standard deviation\n",
        "            noise_std_eve = CustomFunctions.snr_to_noise(7)                                                     # Eve's noise standard deviation\n",
        "            code_word = Models.encoder.predict(data)                                                            # Get the encoded data\n",
        "            rcvd_word = code_word + tf.random.normal(tf.shape(code_word), mean=0.0, stddev=noise_std)           # Add noise\n",
        "            rcvd_word_eve = rcvd_word + tf.random.normal(tf.shape(rcvd_word), mean=0.0, stddev=noise_std_eve)   # Add Eve's noise\n",
        "            dcoded_msg_bob = Models.decoder_bob.predict(rcvd_word)                                              # Decode Bob's received data\n",
        "            dcoded_msg_eve = Models.decoder_eve.predict(rcvd_word_eve)                                          # Decode Eve's received data\n",
        "            bber_vec_bob[db] = CustomFunctions.B_Ber(data, dcoded_msg_bob)                                      # Calculate Bob's Bit Error Rate\n",
        "            bber_vec_eve[db] = CustomFunctions.B_Ber(data, dcoded_msg_eve)                                      # Calculate Eve's Bit Error Rate\n",
        "            print(f'Progress: {db + 1} of {30} parts')                                                          # Display progress\n",
        "        return (snr_range, bber_vec_bob), (snr_range, bber_vec_eve)                                             # Return Bob's and Eve's Bit Error Rates for each SNR\n",
        "#*********************************************************************************************************************************************************************\n",
        "    @staticmethod\n",
        "    def satellite_labels(kmeans_labels, data_label, sats=4, data_size=150000):\n",
        "            code_mat = np.zeros((sats, M_sec))                                                                  # Initialize the code matrix with the specified dimensions\n",
        "            n = np.zeros(sats, dtype=np.int32)                                                                  # Initialize a counter for each satellite\n",
        "            for index in range(M):\n",
        "                sat = kmeans_labels[index]                                                                      # Get the satellite label for the current index\n",
        "                if n[sat] < M_sec:                                                                              # Check if satellite has capacity for more data\n",
        "                    code_mat[sat, n[sat]] = index                                                               # Assign the index to the code matrix for the satellite\n",
        "                    n[sat] += 1                                                                                 # Increment the counter for the satellite\n",
        "            coded_label = np.zeros(data_size)                                                                   # Initialize the coded label array\n",
        "            for i in range(data_size):\n",
        "                aux_var = data_label[i]                                                                         # Get the current data label\n",
        "                coded_label[i] = code_mat[np.random.randint(sats), aux_var]                                     # Assign a code based on random satellite and data label\n",
        "            return coded_label, code_mat                                                                        # Return the coded labels and the code matrix\n",
        "#*********************************************************************************************************************************************************************\n",
        "    @staticmethod\n",
        "    def sec_decoding(code_mat, pred_output, satellites, clusters):\n",
        "            decoded_data = np.zeros(len(pred_output), dtype=int)                                                # Initialize array for decoded data\n",
        "            for i, output in enumerate(pred_output):\n",
        "                found = False                                                                                   # Flag to indicate if the output is found\n",
        "                for cloud in range(satellites):\n",
        "                    for msg in range(clusters):\n",
        "                        if code_mat[cloud, msg] == output:\n",
        "                            decoded_data[i] = msg                                                               # Decode the message\n",
        "                            found = True                                                                        # Set found flag to True\n",
        "                            break\n",
        "                    if found:\n",
        "                        break\n",
        "            return decoded_data                                                                                 # Return the decoded data\n",
        "#*********************************************************************************************************************************************************************\n",
        "    @staticmethod\n",
        "    def Test_secure_AE(coded_data, code_mat, real_data):\n",
        "        '''Calculate symbol error for various SNRs.'''\n",
        "        snr_range = np.linspace(0, 15, 30)                                                                      # Define SNR range\n",
        "        bber_vec_bob = [None] * len(snr_range)                                                                  # Vector for Bob's bit error rate\n",
        "        bber_vec_eve = [None] * len(snr_range)                                                                  # Vector for Eve's bit error rate\n",
        "        for db in range(len(snr_range)):                                                                        # Iterate over SNR range\n",
        "            noise_std = CustomFunctions.snr_to_noise(snr_range[db])\n",
        "            noise_std_eve = CustomFunctions.snr_to_noise(7)\n",
        "            code_word = Models.encoder.predict(coded_data)                                                      # Generate received word with noise for Bob\n",
        "            rcvd_word = code_word + tf.random.normal(tf.shape(code_word), mean=0.0, stddev=noise_std)\n",
        "            rcvd_word_eve = rcvd_word + tf.random.normal(tf.shape(code_word), mean=0.0, stddev=noise_std_eve)   # Generate received word with noise for Eve\n",
        "            pred_msg_bob = Models.decoder_bob.predict(rcvd_word)                                                # Predict messages for Bob and Eve\n",
        "            pred_msg_eve = Models.decoder_eve.predict(rcvd_word_eve)\n",
        "            decoded_msg_bob = Evaluation.sec_decoding(code_mat, np.array(tf.argmax(pred_msg_bob,1)), M_sec, M_sec)  # Decode messages for Bob and Eve\n",
        "            decoded_msg_eve = Evaluation.sec_decoding(code_mat, np.array(tf.argmax(pred_msg_eve,1)), M_sec, M_sec)\n",
        "            bber_vec_bob[db] = np.mean(np.not_equal(decoded_msg_bob, real_data))                                # Calculate bit error rate for Bob and Eve\n",
        "            bber_vec_eve[db] = np.mean(np.not_equal(decoded_msg_eve, real_data))\n",
        "            print(f'Progress: {db+1} of {30} parts')\n",
        "        return (snr_range, bber_vec_bob), (snr_range, bber_vec_eve)                                             # Return Bob's and Eve's bit error rates for the SNR range"
      ],
      "metadata": {
        "id": "sdETOBeQLcCW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_encoding(M=16, n=1):                                                                                   # Function to test encoding\n",
        "    inp = np.eye(M, dtype=int)                                                                                  # Generate identity matrix\n",
        "    coding = Models.encoder.predict(inp)                                                                        # Get encoded representation\n",
        "    fig = plt.figure(figsize=(4,4))                                                                             # Create figure\n",
        "    plt.plot(coding[:,0], coding[:, 1], \"b.\")                                                                   # Plot encoded data points\n",
        "    plt.xlabel(\"$x_1$\", fontsize=18)                                                                            # Set x-axis label\n",
        "    plt.ylabel(\"$x_2$\", fontsize=18, rotation=0)                                                                # Set y-axis label\n",
        "    plt.grid(True)                                                                                              # Show grid\n",
        "    plt.gca().set_ylim(-2, 2)                                                                                   # Set y-axis limits\n",
        "    plt.gca().set_xlim(-2, 2)                                                                                   # Set x-axis limits\n",
        "    plt.show()                                                                                                  # Display plot\n",
        "\n",
        "def test_noisy_codeword(data):                                                                                  # Function to test noisy codeword\n",
        "    rcvd_word = data[1:2000]                                                                                    # Extract received word\n",
        "    fig = plt.figure(figsize=(4,4))                                                                             # Create figure\n",
        "    plt.plot(rcvd_word[:,0], rcvd_word[:, 1], \"b.\")                                                             # Plot received word data points\n",
        "    plt.xlabel(\"$x_1$\", fontsize=18)                                                                            # Set x-axis label\n",
        "    plt.ylabel(\"$x_2$\", fontsize=18, rotation=0)                                                                # Set y-axis label\n",
        "    plt.grid(True)                                                                                              # Show grid\n",
        "    plt.gca().set_ylim(-2, 2)                                                                                   # Set y-axis limits\n",
        "    plt.gca().set_xlim(-2, 2)                                                                                   # Set x-axis limits\n",
        "    plt.show()                                                                                                  # Display plot"
      ],
      "metadata": {
        "id": "beqcGf4wLeuH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "batch_size = 200\n",
        "n_steps = len(data_oneH) // batch_size\n",
        "optimizer = keras.optimizers.Nadam(lr=0.005)\n",
        "loss_fn = keras.losses.categorical_crossentropy\n",
        "mean_loss = keras.metrics.Mean()\n",
        "\n",
        "def plot_loss(step, epoch, mean_loss, X_batch, y_pred, plot_encoding):\n",
        "    template = 'Iteration: {}, Epoch: {}, Loss: {:.5f}, Batch_BER: {:.5f}'                                      # Display iteration results every 10 steps\n",
        "    if step % 10 == 0:\n",
        "        print(template.format(step, epoch, mean_loss.result(), CustomFunctions.B_Ber(X_batch, y_pred)))\n",
        "        if plot_encoding:                                                                                       # Check if encoding plot should be displayed\n",
        "            test_encoding()\n",
        "\n",
        "def plot_batch_loss(epoch, mean_loss, X_batch, y_pred):\n",
        "    template_outer_loop = 'Interim result for Epoch: {}, Loss: {:.5f}, Batch_BER: {:.5f}'                       # Display interim results for the epoch\n",
        "    print(template_outer_loop.format(epoch, mean_loss.result(), CustomFunctions.B_Ber(X_batch, y_pred)))"
      ],
      "metadata": {
        "id": "2rd8xA5eLgoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8428f5-0f2e-4a86-f6ca-a7924fafa079"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test msg sequence for normal encoding\n",
        "N_test = 150000\n",
        "test_msg = np.random.randint(M, size=N_test)\n",
        "one_hot_encoder = OneHotEncoder(sparse=False, categories=[range(M)])\n",
        "data_oh_normal = one_hot_encoder.fit_transform(test_msg.reshape(-1,1))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.005)                                                      # Define and Initialize the optimizer\n",
        "autoencoder_bob = keras.models.Sequential([Models.encoder, Models.decoder_bob])                                 # Create autoencoder models\n",
        "autoencoder_eve = keras.models.Sequential([Models.encoder, Models.decoder_eve])\n",
        "_ = autoencoder_bob(data_oneH[:1])                                                                              # Call models to ensure weights are created\n",
        "_ = autoencoder_eve(data_oneH[:1])\n",
        "# Build the optimizer after the models' weights have been created\n",
        "optimizer.apply_gradients([(tf.zeros_like(var), var) for var in autoencoder_bob.trainable_variables + autoencoder_eve.trainable_variables])\n",
        "\n",
        "Training.train_Bob(n_epochs, n_steps, False, False)                                                             # Use the built optimizer in the training loops\n",
        "Training.train_Eve(n_epochs-1, n_steps, False)                                                                  # reduced epochs to match accuracy of both\n",
        "bber_data_bob, bber_data_eve = Evaluation.Test_AE(data_oh_normal)                                               # Test the autoencoder models with normal data\n",
        "kmeans = Training.init_kmeans(M, M_sec, n)                                                                      # Initialize kmeans for the security procedure\n",
        "Training.train_Secure(kmeans.labels_, n_epochs-3, n_steps, 0.3, False)                                          # Train the secure model\n",
        "Training.train_Bob(n_epochs-2, n_steps, False, True)\n",
        "Training.train_Eve(n_epochs-3, n_steps, False)\n",
        "\n",
        "# test msg sequence for secure encoding\n",
        "N_test_sec = 150000\n",
        "test_msg_sec = np.random.randint(M_sec, size=N_test_sec)\n",
        "print('Mapping real symbols onto secure symbols')\n",
        "coded_msg, code_matrix = Evaluation.satellite_labels(kmeans.labels_, test_msg_sec,M_sec, N_test_sec)\n",
        "one_hot_encoder_sec = OneHotEncoder(sparse=False, categories=[range(M)])\n",
        "data_oh_sec = one_hot_encoder_sec.fit_transform(coded_msg.reshape(-1,1))\n",
        "print(\"Testing the secure symbols\")\n",
        "bber_sec_bob, bber_sec_eve = Evaluation.Test_secure_AE(data_oh_sec, code_matrix, test_msg_sec)"
      ],
      "metadata": {
        "id": "qZ8M0RIBLi__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0cf6606-48cc-43e2-bf19-06422265789f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bob in Epoch 1/5\n",
            "Iteration: 10, Epoch: 1, Loss: 2.30646, Batch_BER: 0.43500\n",
            "Iteration: 20, Epoch: 1, Loss: 1.71945, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 1, Loss: 1.29363, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 1, Loss: 1.00943, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 1, Loss: 0.82123, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 1, Loss: 0.69065, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 1, Loss: 0.59549, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 1, Loss: 0.52330, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 1, Loss: 0.46672, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 1, Loss: 0.42121, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 1, Loss: 0.38380, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 1, Loss: 0.35252, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 1, Loss: 0.32598, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 1, Loss: 0.30317, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 1, Loss: 0.28335, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 1, Loss: 0.26596, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 1, Loss: 0.25060, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 1, Loss: 0.23691, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 1, Loss: 0.22465, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 1, Loss: 0.21360, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 1, Loss: 0.20358, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 1, Loss: 0.19447, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 1, Loss: 0.18613, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 1, Loss: 0.17849, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 1, Loss: 0.17144, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 1, Loss: 0.17144, Batch_BER: 0.00000\n",
            "Training Bob in Epoch 2/5\n",
            "Iteration: 10, Epoch: 2, Loss: 0.16494, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 2, Loss: 0.15891, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 2, Loss: 0.15331, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 2, Loss: 0.14809, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 2, Loss: 0.14321, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 2, Loss: 0.13864, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 2, Loss: 0.13436, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 2, Loss: 0.13034, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 2, Loss: 0.12655, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 2, Loss: 0.12297, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 2, Loss: 0.11959, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 2, Loss: 0.11639, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 2, Loss: 0.11336, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 2, Loss: 0.11048, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 2, Loss: 0.10775, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 2, Loss: 0.10514, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 2, Loss: 0.10267, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 2, Loss: 0.10030, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 2, Loss: 0.09804, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 2, Loss: 0.09588, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 2, Loss: 0.09382, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 2, Loss: 0.09184, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 2, Loss: 0.08994, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 2, Loss: 0.08812, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 2, Loss: 0.08637, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 2, Loss: 0.08637, Batch_BER: 0.00000\n",
            "Training Bob in Epoch 3/5\n",
            "Iteration: 10, Epoch: 3, Loss: 0.08469, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 3, Loss: 0.08308, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 3, Loss: 0.08152, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 3, Loss: 0.08002, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 3, Loss: 0.07858, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 3, Loss: 0.07719, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 3, Loss: 0.07584, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 3, Loss: 0.07455, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 3, Loss: 0.07329, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 3, Loss: 0.07208, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 3, Loss: 0.07091, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 3, Loss: 0.06977, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 3, Loss: 0.06867, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 3, Loss: 0.06760, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 3, Loss: 0.06657, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 3, Loss: 0.06557, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 3, Loss: 0.06460, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 3, Loss: 0.06365, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 3, Loss: 0.06274, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 3, Loss: 0.06185, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 3, Loss: 0.06098, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 3, Loss: 0.06014, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 3, Loss: 0.05932, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 3, Loss: 0.05852, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 3, Loss: 0.05775, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 3, Loss: 0.05775, Batch_BER: 0.00000\n",
            "Training Bob in Epoch 4/5\n",
            "Iteration: 10, Epoch: 4, Loss: 0.05699, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 4, Loss: 0.05626, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 4, Loss: 0.05554, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 4, Loss: 0.05484, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 4, Loss: 0.05416, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 4, Loss: 0.05349, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 4, Loss: 0.05285, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 4, Loss: 0.05221, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 4, Loss: 0.05159, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 4, Loss: 0.05099, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 4, Loss: 0.05040, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 4, Loss: 0.04982, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 4, Loss: 0.04926, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 4, Loss: 0.04871, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 4, Loss: 0.04817, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 4, Loss: 0.04765, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 4, Loss: 0.04713, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 4, Loss: 0.04663, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 4, Loss: 0.04613, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 4, Loss: 0.04565, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 4, Loss: 0.04518, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 4, Loss: 0.04471, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 4, Loss: 0.04426, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 4, Loss: 0.04381, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 4, Loss: 0.04338, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 4, Loss: 0.04338, Batch_BER: 0.00000\n",
            "Training Bob in Epoch 5/5\n",
            "Iteration: 10, Epoch: 5, Loss: 0.04295, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 5, Loss: 0.04253, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 5, Loss: 0.04212, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 5, Loss: 0.04172, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 5, Loss: 0.04132, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 5, Loss: 0.04093, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 5, Loss: 0.04055, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 5, Loss: 0.04018, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 5, Loss: 0.03981, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 5, Loss: 0.03945, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 5, Loss: 0.03910, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 5, Loss: 0.03875, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 5, Loss: 0.03841, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 5, Loss: 0.03807, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 5, Loss: 0.03774, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 5, Loss: 0.03742, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 5, Loss: 0.03710, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 5, Loss: 0.03679, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 5, Loss: 0.03648, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 5, Loss: 0.03618, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 5, Loss: 0.03588, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 5, Loss: 0.03559, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 5, Loss: 0.03530, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 5, Loss: 0.03501, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 5, Loss: 0.03473, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 5, Loss: 0.03473, Batch_BER: 0.00000\n",
            "Training Eve in Epoch 1/4\n",
            "Iteration: 10, Epoch: 1, Loss: 0.04453, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 1, Loss: 0.04446, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 1, Loss: 0.04413, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 1, Loss: 0.04379, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 1, Loss: 0.04345, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 1, Loss: 0.04313, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 1, Loss: 0.04280, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 1, Loss: 0.04248, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 1, Loss: 0.04217, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 1, Loss: 0.04186, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 1, Loss: 0.04155, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 1, Loss: 0.04125, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 1, Loss: 0.04095, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 1, Loss: 0.04066, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 1, Loss: 0.04037, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 1, Loss: 0.04008, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 1, Loss: 0.03980, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 1, Loss: 0.03953, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 1, Loss: 0.03925, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 1, Loss: 0.03898, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 1, Loss: 0.03872, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 1, Loss: 0.03846, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 1, Loss: 0.03820, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 1, Loss: 0.03794, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 1, Loss: 0.03769, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 1, Loss: 0.03769, Batch_BER: 0.00000\n",
            "Training Eve in Epoch 2/4\n",
            "Iteration: 10, Epoch: 2, Loss: 0.03744, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 2, Loss: 0.03720, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 2, Loss: 0.03696, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 2, Loss: 0.03672, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 2, Loss: 0.03648, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 2, Loss: 0.03625, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 2, Loss: 0.03602, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 2, Loss: 0.03579, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 2, Loss: 0.03557, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 2, Loss: 0.03535, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 2, Loss: 0.03513, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 2, Loss: 0.03491, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 2, Loss: 0.03470, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 2, Loss: 0.03449, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 2, Loss: 0.03428, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 2, Loss: 0.03407, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 2, Loss: 0.03387, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 2, Loss: 0.03367, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 2, Loss: 0.03347, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 2, Loss: 0.03328, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 2, Loss: 0.03308, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 2, Loss: 0.03289, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 2, Loss: 0.03270, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 2, Loss: 0.03251, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 2, Loss: 0.03233, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 2, Loss: 0.03233, Batch_BER: 0.00000\n",
            "Training Eve in Epoch 3/4\n",
            "Iteration: 10, Epoch: 3, Loss: 0.03214, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 3, Loss: 0.03196, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 3, Loss: 0.03178, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 3, Loss: 0.03161, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 3, Loss: 0.03143, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 3, Loss: 0.03126, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 3, Loss: 0.03109, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 3, Loss: 0.03092, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 3, Loss: 0.03075, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 3, Loss: 0.03059, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 3, Loss: 0.03042, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 3, Loss: 0.03026, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 3, Loss: 0.03010, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 3, Loss: 0.02994, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 3, Loss: 0.02978, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 3, Loss: 0.02963, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 3, Loss: 0.02947, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 3, Loss: 0.02932, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 3, Loss: 0.02917, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 3, Loss: 0.02902, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 3, Loss: 0.02888, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 3, Loss: 0.02873, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 3, Loss: 0.02858, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 3, Loss: 0.02844, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 3, Loss: 0.02830, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 3, Loss: 0.02830, Batch_BER: 0.00000\n",
            "Training Eve in Epoch 4/4\n",
            "Iteration: 10, Epoch: 4, Loss: 0.02816, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 4, Loss: 0.02802, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 4, Loss: 0.02788, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 4, Loss: 0.02775, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 4, Loss: 0.02761, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 4, Loss: 0.02748, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 4, Loss: 0.02734, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 4, Loss: 0.02721, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 4, Loss: 0.02708, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 4, Loss: 0.02696, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 4, Loss: 0.02683, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 4, Loss: 0.02670, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 4, Loss: 0.02658, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 4, Loss: 0.02645, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 4, Loss: 0.02633, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 4, Loss: 0.02621, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 4, Loss: 0.02609, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 4, Loss: 0.02597, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 4, Loss: 0.02585, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 4, Loss: 0.02573, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 4, Loss: 0.02562, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 4, Loss: 0.02550, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 4, Loss: 0.02539, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 4, Loss: 0.02528, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 4, Loss: 0.02516, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 4, Loss: 0.02516, Batch_BER: 0.00000\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 1 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 2 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 10s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 3 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 4 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 5 of 30 parts\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 6 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 7 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 8 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 9 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 10s 2ms/step\n",
            "Progress: 10 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 11 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 1ms/step\n",
            "Progress: 12 of 30 parts\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 13 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 1ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 14 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 15 of 30 parts\n",
            "4688/4688 [==============================] - 7s 1ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 16 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 17 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 18 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 10s 2ms/step\n",
            "Progress: 19 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 20 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 21 of 30 parts\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 22 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 1ms/step\n",
            "Progress: 23 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 24 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 25 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 26 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 27 of 30 parts\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 28 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 29 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 30 of 30 parts\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "Training for Security in Epoch 1/2\n",
            "Iteration: 10, Epoch: 1, Loss: 0.03366, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 1, Loss: 0.03738, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 1, Loss: 0.04068, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 1, Loss: 0.04387, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 1, Loss: 0.04702, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 1, Loss: 0.05006, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 1, Loss: 0.05306, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 1, Loss: 0.05601, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 1, Loss: 0.05897, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 1, Loss: 0.06201, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 1, Loss: 0.06488, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 1, Loss: 0.06771, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 1, Loss: 0.07051, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 1, Loss: 0.07337, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 1, Loss: 0.07617, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 1, Loss: 0.07889, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 1, Loss: 0.08163, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 1, Loss: 0.08427, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 1, Loss: 0.08688, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 1, Loss: 0.08962, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 1, Loss: 0.09233, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 1, Loss: 0.09500, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 1, Loss: 0.09760, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 1, Loss: 0.10013, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 1, Loss: 0.10266, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 1, Loss: 0.10266, Batch_BER: 0.00000\n",
            "Training for Security in Epoch 2/2\n",
            "Iteration: 10, Epoch: 2, Loss: 0.10516, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 2, Loss: 0.10759, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 2, Loss: 0.11014, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 2, Loss: 0.11262, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 2, Loss: 0.11503, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 2, Loss: 0.11740, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 2, Loss: 0.11981, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 2, Loss: 0.12217, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 2, Loss: 0.12451, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 2, Loss: 0.12687, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 2, Loss: 0.12926, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 2, Loss: 0.13160, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 2, Loss: 0.13383, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 2, Loss: 0.13612, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 2, Loss: 0.13842, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 2, Loss: 0.14058, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 2, Loss: 0.14279, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 2, Loss: 0.14502, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 2, Loss: 0.14725, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 2, Loss: 0.14940, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 2, Loss: 0.15154, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 2, Loss: 0.15368, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 2, Loss: 0.15581, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 2, Loss: 0.15791, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 2, Loss: 0.16003, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 2, Loss: 0.16003, Batch_BER: 0.00000\n",
            "Training Bob in Epoch 1/3\n",
            "Iteration: 10, Epoch: 1, Loss: 0.15946, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 1, Loss: 0.15889, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 1, Loss: 0.15832, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 1, Loss: 0.15776, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 1, Loss: 0.15720, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 1, Loss: 0.15665, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 1, Loss: 0.15609, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 1, Loss: 0.15555, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 1, Loss: 0.15500, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 1, Loss: 0.15446, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 1, Loss: 0.15392, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 1, Loss: 0.15339, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 1, Loss: 0.15286, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 1, Loss: 0.15233, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 1, Loss: 0.15181, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 1, Loss: 0.15129, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 1, Loss: 0.15077, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 1, Loss: 0.15026, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 1, Loss: 0.14975, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 1, Loss: 0.14925, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 1, Loss: 0.14874, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 1, Loss: 0.14825, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 1, Loss: 0.14775, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 1, Loss: 0.14726, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 1, Loss: 0.14677, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 1, Loss: 0.14677, Batch_BER: 0.00000\n",
            "Training Bob in Epoch 2/3\n",
            "Iteration: 10, Epoch: 2, Loss: 0.14628, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 2, Loss: 0.14580, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 2, Loss: 0.14532, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 2, Loss: 0.14484, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 2, Loss: 0.14437, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 2, Loss: 0.14390, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 2, Loss: 0.14343, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 2, Loss: 0.14297, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 2, Loss: 0.14250, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 2, Loss: 0.14205, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 2, Loss: 0.14159, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 2, Loss: 0.14114, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 2, Loss: 0.14069, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 2, Loss: 0.14024, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 2, Loss: 0.13980, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 2, Loss: 0.13935, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 2, Loss: 0.13892, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 2, Loss: 0.13848, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 2, Loss: 0.13805, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 2, Loss: 0.13762, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 2, Loss: 0.13719, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 2, Loss: 0.13676, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 2, Loss: 0.13634, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 2, Loss: 0.13592, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 2, Loss: 0.13550, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 2, Loss: 0.13550, Batch_BER: 0.00000\n",
            "Training Bob in Epoch 3/3\n",
            "Iteration: 10, Epoch: 3, Loss: 0.13509, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 3, Loss: 0.13468, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 3, Loss: 0.13427, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 3, Loss: 0.13386, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 3, Loss: 0.13345, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 3, Loss: 0.13305, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 3, Loss: 0.13265, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 3, Loss: 0.13225, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 3, Loss: 0.13186, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 3, Loss: 0.13146, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 3, Loss: 0.13107, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 3, Loss: 0.13069, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 3, Loss: 0.13030, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 3, Loss: 0.12992, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 3, Loss: 0.12953, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 3, Loss: 0.12916, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 3, Loss: 0.12878, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 3, Loss: 0.12840, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 3, Loss: 0.12803, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 3, Loss: 0.12766, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 3, Loss: 0.12729, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 3, Loss: 0.12692, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 3, Loss: 0.12656, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 3, Loss: 0.12620, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 3, Loss: 0.12584, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 3, Loss: 0.12584, Batch_BER: 0.00000\n",
            "Training Eve in Epoch 1/2\n",
            "Iteration: 10, Epoch: 1, Loss: 0.12845, Batch_BER: 0.04000\n",
            "Iteration: 20, Epoch: 1, Loss: 0.12858, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 1, Loss: 0.12832, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 1, Loss: 0.12799, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 1, Loss: 0.12766, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 1, Loss: 0.12732, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 1, Loss: 0.12698, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 1, Loss: 0.12664, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 1, Loss: 0.12630, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 1, Loss: 0.12596, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 1, Loss: 0.12562, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 1, Loss: 0.12529, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 1, Loss: 0.12495, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 1, Loss: 0.12462, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 1, Loss: 0.12428, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 1, Loss: 0.12395, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 1, Loss: 0.12362, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 1, Loss: 0.12329, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 1, Loss: 0.12296, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 1, Loss: 0.12264, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 1, Loss: 0.12231, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 1, Loss: 0.12199, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 1, Loss: 0.12167, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 1, Loss: 0.12135, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 1, Loss: 0.12103, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 1, Loss: 0.12103, Batch_BER: 0.00000\n",
            "Training Eve in Epoch 2/2\n",
            "Iteration: 10, Epoch: 2, Loss: 0.12071, Batch_BER: 0.00000\n",
            "Iteration: 20, Epoch: 2, Loss: 0.12040, Batch_BER: 0.00000\n",
            "Iteration: 30, Epoch: 2, Loss: 0.12008, Batch_BER: 0.00000\n",
            "Iteration: 40, Epoch: 2, Loss: 0.11977, Batch_BER: 0.00000\n",
            "Iteration: 50, Epoch: 2, Loss: 0.11946, Batch_BER: 0.00000\n",
            "Iteration: 60, Epoch: 2, Loss: 0.11915, Batch_BER: 0.00000\n",
            "Iteration: 70, Epoch: 2, Loss: 0.11884, Batch_BER: 0.00000\n",
            "Iteration: 80, Epoch: 2, Loss: 0.11853, Batch_BER: 0.00000\n",
            "Iteration: 90, Epoch: 2, Loss: 0.11823, Batch_BER: 0.00000\n",
            "Iteration: 100, Epoch: 2, Loss: 0.11792, Batch_BER: 0.00000\n",
            "Iteration: 110, Epoch: 2, Loss: 0.11762, Batch_BER: 0.00000\n",
            "Iteration: 120, Epoch: 2, Loss: 0.11732, Batch_BER: 0.00000\n",
            "Iteration: 130, Epoch: 2, Loss: 0.11702, Batch_BER: 0.00000\n",
            "Iteration: 140, Epoch: 2, Loss: 0.11672, Batch_BER: 0.00000\n",
            "Iteration: 150, Epoch: 2, Loss: 0.11643, Batch_BER: 0.00000\n",
            "Iteration: 160, Epoch: 2, Loss: 0.11613, Batch_BER: 0.00000\n",
            "Iteration: 170, Epoch: 2, Loss: 0.11584, Batch_BER: 0.00000\n",
            "Iteration: 180, Epoch: 2, Loss: 0.11555, Batch_BER: 0.00000\n",
            "Iteration: 190, Epoch: 2, Loss: 0.11526, Batch_BER: 0.00000\n",
            "Iteration: 200, Epoch: 2, Loss: 0.11497, Batch_BER: 0.00000\n",
            "Iteration: 210, Epoch: 2, Loss: 0.11468, Batch_BER: 0.00000\n",
            "Iteration: 220, Epoch: 2, Loss: 0.11439, Batch_BER: 0.00000\n",
            "Iteration: 230, Epoch: 2, Loss: 0.11411, Batch_BER: 0.00000\n",
            "Iteration: 240, Epoch: 2, Loss: 0.11382, Batch_BER: 0.00000\n",
            "Iteration: 250, Epoch: 2, Loss: 0.11354, Batch_BER: 0.00000\n",
            "Interim result for Epoch: 2, Loss: 0.11354, Batch_BER: 0.00000\n",
            "Mapping real symbols onto secure symbols\n",
            "Testing the secure symbols\n",
            "  37/4688 [..............................] - ETA: 6s  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 1 of 30 parts\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 2 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 1ms/step\n",
            "Progress: 3 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 4 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 5 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 6 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 7 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 8 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 9 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 10 of 30 parts\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 11 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 12 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 13 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 14 of 30 parts\n",
            "4688/4688 [==============================] - 10s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 15 of 30 parts\n",
            "4688/4688 [==============================] - 7s 1ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 16 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 17 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 18 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 19 of 30 parts\n",
            "4688/4688 [==============================] - 10s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 20 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 21 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "Progress: 22 of 30 parts\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 23 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "Progress: 24 of 30 parts\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 7s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 25 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 26 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 10s 2ms/step\n",
            "Progress: 27 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 28 of 30 parts\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 29 of 30 parts\n",
            "4688/4688 [==============================] - 9s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "4688/4688 [==============================] - 8s 2ms/step\n",
            "Progress: 30 of 30 parts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8, 5))\n",
        "plt.semilogy(bber_data_bob[0], bber_data_bob[1], 'o-')                                                       # Plot different curves\n",
        "plt.semilogy(bber_data_eve[0], bber_data_eve[1], 's-')\n",
        "plt.semilogy(bber_sec_bob[0], bber_sec_bob[1], '^-')\n",
        "plt.semilogy(bber_sec_eve[0], bber_sec_eve[1], '^-')\n",
        "plt.gca().set_ylim(1e-5, 1)                                                                                  # Set y-axis limits and x-axis limits\n",
        "plt.gca().set_xlim(0, 15)\n",
        "plt.tick_params(axis='x', colors='white')                                                                    # Set tick colors\n",
        "plt.tick_params(axis='y', colors='white')\n",
        "plt.ylabel(\"Batch Symbol Error Rate\", fontsize=14, rotation=90, color='white')                               # Set labels and legend\n",
        "plt.xlabel(\"SNR [dB]\", fontsize=18, color='white')\n",
        "plt.legend(['AE Bob', 'AE Eve', 'Secure AE Bob', 'Secure AE Eve'], prop={'size': 14}, loc='upper right')\n",
        "plt.grid(True, which=\"both\")                                                                                 # Add grid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "Vft-tqmBObv9",
        "outputId": "1ca2551d-b646-460e-b3b1-4b80c33b8412"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}